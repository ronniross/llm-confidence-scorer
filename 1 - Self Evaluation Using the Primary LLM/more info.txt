1. Load the Model: You need the model before you can use it.

2. Set Prompt/Context: Providing a system prompt helps guide the model's behavior.

3. Initial Inference: This is where the model generates the primary response to the user's query.

4. Self-Evaluation: This step takes the original query and the model's response and formats them 
into a new prompt designed to evaluate the response (in this case, for accuracy).

Keep in mind that the files currently contain conceptual descriptions and placeholders ({here your logic...}, Example (conceptual):) rather than complete, runnable code for the LLM operations themselves. However, the sequence of steps and the purpose of each cell are well-defined for a prototype aiming to test this self-evaluation approach.

This prototype is designed so you can simply paste your current scripts into the coder-model of your choice—whether it's an agent, API, web interface, or one loaded on your own hardware. 

You can then just ask the model to adapt using the proposed prototype. 

This first option is a really simple approach that repeats the query after the initial processing, using the same model for self-evaluation.

Many corporations already have similar systems deployed, but since companies do not display their auxiliary system scripts, at least for now, I am sharing mine.

Ronni Ross
2025
Φ
https://github.com/ronniross
